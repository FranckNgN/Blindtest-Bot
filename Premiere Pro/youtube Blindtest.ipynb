{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "\n",
    "import pymiere\n",
    "from pymiere import wrappers\n",
    "from pymiere.wrappers import get_system_sequence_presets\n",
    "from pymiere.wrappers import time_from_seconds    \n",
    "from pymiere.wrappers import check_active_sequence\n",
    "from pymiere.wrappers import list_sequences\n",
    "from pymiere.wrappers import list_video\n",
    "from pymiere.wrappers import edit_clip\n",
    "from pymiere.exe_utils import start_premiere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getListOfFiles(dirName):\n",
    "    # create a list of file and sub directories \n",
    "    # names in the given directory \n",
    "    listOfFile = os.listdir(dirName)\n",
    "    allFiles = list()\n",
    "    # Iterate over all the entries\n",
    "    for entry in listOfFile:\n",
    "        # Create full path\n",
    "        fullPath = os.path.join(dirName, entry)\n",
    "        # If entry is a directory then get the list of files in this directory \n",
    "        if os.path.isdir(fullPath):\n",
    "            allFiles = allFiles + getListOfFiles(fullPath)\n",
    "        else:\n",
    "            allFiles.append(fullPath)\n",
    "                \n",
    "    return allFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildAnimeDicPath(animeSongPath):\n",
    "    animeFolderList = [ f.path for f in os.scandir(animeSongPath) if f.is_dir() ]#os.listdir(animeSongPath)\n",
    "    animeDicPath = {}\n",
    "\n",
    "    for folder in os.listdir(animeSongPath): # build dictionnary of anime folder and song path in\n",
    "        animeDicPath[folder]= [ f.path for f in os.scandir(animeSongPath + '\\\\' + folder) if f.is_file() ]\n",
    "\n",
    "    return animeDicPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRandomSongPath(animeDicPath, batchNumber, songByBatch):# Create a dictionary of list of song \n",
    "    blindTestSongDic = {}\n",
    "    blindTestSongDic = {'blindTest ' + str(i): [] for i in range(1,batchNumber +1)} # inizialise number of batch\n",
    "\n",
    "    for key, value in blindTestSongDic.items():\n",
    "        for songIndex in range(songByBatch):# Number of song in a batch\n",
    "            \n",
    "            playlist = list(animeDicPath.keys())\n",
    "            animeNumber = len(playlist)\n",
    "            \n",
    "            playlist = playlist[random.randint(0,animeNumber)-1]#get a random anime\n",
    "            songPathList = animeDicPath[playlist] #get list of song path for that playlist\n",
    "            playlistSongNumber = len(songPathList) #get number of song for that anime\n",
    "\n",
    "            if playlistSongNumber != 0: #Folder has to have a song DL at the begining\n",
    "                print\n",
    "                song = songPathList[random.randint(0,playlistSongNumber)-1]\n",
    "\n",
    "                animeDicPath[playlist].remove(song)\n",
    "                if len(animeDicPath[playlist]) == 0:\n",
    "                    animeDicPath.pop(playlist)\n",
    "                blindTestSongDic[key].append(song)\n",
    "            else:\n",
    "                print('No song in the playlist at the begining: ', playlist)\n",
    "                animeDicPath.pop(playlist)\n",
    "                pass\n",
    "\n",
    "\n",
    "    return blindTestSongDic #TODO: CAN HAVE SAME SONG, TO CHECK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trim block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLastClip(sequence,videoTrackIndex):\n",
    "    #Video\n",
    "    lastClipVideo = sequence.videoTracks[videoTrackIndex].clips[-1]\n",
    "\n",
    "    #Audio\n",
    "    lastClipAudio = sequence.audioTracks[videoTrackIndex].clips[-1]\n",
    "\n",
    "    return lastClipVideo, lastClipAudio\n",
    "\n",
    "def trimEnd(videoClip, audioClip, videoClipTrack3 = None, audioClipTrack3 = None, endShift = 0):\n",
    "    if videoClipTrack3 and audioClipTrack3: # If a countdown clip exists, then trim w.r.t\n",
    "        #Video\n",
    "        videoClip.end = time_from_seconds(videoClipTrack3.end.seconds + endShift)\n",
    "\n",
    "        #Audio\n",
    "        audioClip.end = time_from_seconds(audioClipTrack3.end.seconds + endShift)\n",
    "    else: # If none, then flat trim\n",
    "        #Video\n",
    "        videoClip.end = time_from_seconds(videoClip.end.seconds - endShift)\n",
    "\n",
    "        #Audio\n",
    "        audioClip.end = time_from_seconds(audioClip.end.seconds - endShift)\n",
    "\n",
    "def trimStart(videoClip, audioClip, startShift):\n",
    "    # fpsClip = lastClipVideo.projectItem.getFootageInterpretation().frameRate\n",
    "    # shiftFrame = cutStartSecond * fpsClip\n",
    "    # lenClip = lastClipVideo.end.seconds - lastClipVideo.start.seconds\n",
    "\n",
    "    #Move clip LEFT\n",
    "    # try:\n",
    "    #     edit_clip(lastClipVideo, start_on_timeline=round(sequence.videoTracks[1].clips[-1].end.seconds*fpsClip), end_on_timeline=(lenClip-cutStartSecond)*fpsClip + round(sequence.videoTracks[1].clips[-1].end.seconds*fpsClip), in_point_on_clip=cutStartSecond*fpsClip, out_point_on_clip=(lenClip)*fpsClip, fps = fpsClip)\n",
    "    #     edit_clip(lastClipAudio, start_on_timeline=round(sequence.videoTracks[1].clips[-1].end.seconds*fpsClip), end_on_timeline=(lenClip-cutStartSecond)*fpsClip + round(sequence.videoTracks[1].clips[-1].end.seconds*fpsClip), in_point_on_clip=cutStartSecond*fpsClip, out_point_on_clip=(lenClip)*fpsClip, fps = fpsClip)\n",
    "    # except:                    \n",
    "    #     edit_clip(lastClipVideo, start_on_timeline=0, end_on_timeline=(lenClip-cutStartSecond)*fpsClip + 0, in_point_on_clip=cutStartSecond*fpsClip, out_point_on_clip=(lenClip)*fpsClip, fps = fpsClip)\n",
    "    #     edit_clip(lastClipAudio, start_on_timeline=0, end_on_timeline=(lenClip-cutStartSecond)*fpsClip + 0, in_point_on_clip=cutStartSecond*fpsClip, out_point_on_clip=(lenClip)*fpsClip, fps = fpsClip)\n",
    "    pass\n",
    "\n",
    "def trimClip(videoClip, audioClip, videoClipTrack3 = None, audioClipTrack3 = None, startShift = 0, endShift = 0):#TO MODIFY\n",
    "    if startShift != 0:\n",
    "        trimStart(videoClip, audioClip, startShift)\n",
    "    if endShift != 0:\n",
    "        trimEnd(videoClip, audioClip, videoClipTrack3, audioClipTrack3, endShift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVideoRes(videoPath):#TODO: Find a way to get clip resolution through premiere pro and not windows, to rename getClipRes\n",
    "    vcap = cv2.VideoCapture(videoPath) # 0=camera\n",
    " \n",
    "    if vcap.isOpened(): \n",
    "        # get vcap property \n",
    "        width  = int(vcap.get(3))  # float `width`\n",
    "        height = int(vcap.get(4))  # float `height`\n",
    "        fps = vcap.get(5)\n",
    "\n",
    "    return width, height, fps\n",
    "\n",
    "def getSequenceRes(sequence):\n",
    "    return sequence.frameSizeHorizontal, sequence.frameSizeVertical, 0 #TODO: find Sequence FPS\n",
    "\n",
    "def getSeqClipRatio(sequence, videoPath):\n",
    "    sequenceWidth,sequenceHeight, sequenceFPS = getSequenceRes(sequence)\n",
    "    videoWidth, videoHeight, videoFPS = getVideoRes(videoPath)\n",
    "\n",
    "    sequenceRes = sequenceWidth * sequenceHeight\n",
    "    videoRes = videoWidth * videoHeight\n",
    "\n",
    "    seqVidRatio = sequenceWidth/videoWidth*100#sequenceRes / videoRes * 100 # transform as percentage\n",
    "\n",
    "    return seqVidRatio\n",
    "\n",
    "def adjustScaleClip(clip, scaleValue):\n",
    "    for component in clip.components:  \n",
    "        if component.displayName == 'Motion':\n",
    "            for property in component.properties:\n",
    "                #print(property.displayName)\n",
    "                if property.displayName == 'Scale':\n",
    "                    property.setValue(scaleValue, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMainClip(project, sequence, blindTestList, fxDic, doCut):\n",
    "    cutStartSecond, cutEndSecond = 0, 5 #TODO: if cutStartSecond !=0, video are not synchronised\n",
    "\n",
    "    countDownVideoTrack = 2 \n",
    "\n",
    "    for index, songPath in enumerate(blindTestList):\n",
    "        #Import video on main track\n",
    "        songItem = project.rootItem.findItemsMatchingMediaPath(songPath, ignoreSubclips=False)[0]\n",
    "        try:\n",
    "            sequence.insertClip(songItem, time_from_seconds(sequence.videoTracks[countDownVideoTrack].clips[-1].end.seconds),0, 0)\n",
    "        except:\n",
    "            sequence.insertClip(songItem, time_from_seconds(0),0, 0)\n",
    "\n",
    "        lastClipVideo, lastClipAudio = getLastClip(sequence,videoTrackIndex = 0)\n",
    "        \n",
    "        #Adjust ratio if width are different\n",
    "        ratio = getSeqClipRatio(sequence, songPath)\n",
    "        adjustScaleClip(lastClipVideo, ratio)\n",
    "\n",
    "        if ratio != 100:\n",
    "            print(ratio)\n",
    "\n",
    "        sequence.insertClip(project.rootItem.findItemsMatchingMediaPath(fxDic[1], ignoreSubclips=False)[0], time_from_seconds(sequence.videoTracks[0].clips[-1].start.seconds), countDownVideoTrack, countDownVideoTrack)\n",
    "        #sequence.insertClip(project.rootItem.findItemsMatchingMediaPath(fxDic[2], ignoreSubclips=False)[0], time_from_seconds(sequence.videoTracks[countDownVideoTrack].clips[-1].end.seconds), countDownVideoTrack, countDownVideoTrack)\n",
    "\n",
    "        if doCut: #cut clip start and end\n",
    "            lastClipVideo3, lastClipAudio3 = getLastClip(sequence,videoTrackIndex = countDownVideoTrack)\n",
    "            #lastClipVideo3, lastClipAudio3 = None, None\n",
    "            trimClip(lastClipVideo, lastClipAudio, lastClipVideo3, lastClipAudio3, cutStartSecond, cutEndSecond)#TODO: TO MODIFY, CUT DOES NOT WORK AS INTENDED\n",
    "\n",
    "        #Waiting video in between main clip, This need to be last on the task list\n",
    "        if index < len(blindTestList)-1:#Do not create waiting countdown at the last video\n",
    "            sequence.insertClip(project.rootItem.findItemsMatchingMediaPath(fxDic[0], ignoreSubclips=False)[0], time_from_seconds(sequence.videoTracks[0].clips[-1].end.seconds), countDownVideoTrack,  countDownVideoTrack) \n",
    "\n",
    "        sequence.audioTracks[countDownVideoTrack].setMute(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "animeSongPath = r\"D:\\Videos\\Blind Test\\Anime\"\n",
    "animeSongList = getListOfFiles(animeSongPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "doGetRandomSong = True\n",
    "\n",
    "batchNumber = 5\n",
    "songByBatch = 5\n",
    "\n",
    "if doGetRandomSong:\n",
    "    animeDicPath = buildAnimeDicPath(animeSongPath)\n",
    "    blindTestSongDic = getRandomSongPath(animeDicPath, batchNumber, songByBatch)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blindTest 1': ['D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Dr Stone\\\\ＴＶアニメ 「Ｄｒ．ＳＴＯＮＥ」 第2クールOP＜三原色＞ノンクレジット映像.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Love is War\\\\Chika Dance.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Monster\\\\Monster Opening HD.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Shokugeki no Soma\\\\Food Wars! The Fourth Plate - Opening (HD).mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Tokyo Revengers\\\\Tokyo Revengers - Opening  Cry Baby.mp4'],\n",
       " 'blindTest 2': ['D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Naruto\\\\Naruto Opening 6  No Boy No Cry (HD).mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Arslan Senki\\\\Arslan senki ending 1.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Prison School\\\\Prison School - Opening HD.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\SNK\\\\Attack on Titans OST - Erens Berserk Theme.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Yakusoku no Neverland\\\\The Promised Neverland OST - Isabella’s Lullaby.mp4'],\n",
       " 'blindTest 3': ['D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Ken le Survivant\\\\Générique  Ken le Survivant.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Love is War\\\\Kaguya-sama Love is War Opening - Love Dramatic [TV Broadcast Version1080pEnglish CC].mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Samurai Shamploo\\\\Nujabes- Mystline [Full Version].mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Tengen Toppa Gurren Lagann\\\\Tengen Toppa Gurren Lagann-Sorairo Days (Opening 1).mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Tokyo Revengers\\\\Tokyo Revengers - Ending  Koko de Iki o Shite.mp4'],\n",
       " 'blindTest 4': ['D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Hunter x Hunter\\\\Hunter X Hunter - Ending 5  Hyori Ittai.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Mononoke Hime\\\\Princess Mononoke Main Theme.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Shaman King21\\\\TVアニメ『SHAMAN KING』ノンクレジットオープニング｜2021年4月1日放送開始.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Code Breaker\\\\Code Breaker Opening.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Sword Art Online\\\\「Creditless」Sword Art Online II OP  Opening 1「UHD 60FPS」.mp4'],\n",
       " 'blindTest 5': ['D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Naruto Shippuden\\\\Naruto Shippuden Ending 6  Broken Youth (HD).mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Bakuman\\\\Bakuman S2 OP2 - Dream of Life English Lyrics (Season  Series 2 Opening + Subtitles).mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Chainsaw Man\\\\「Creditless」Chainsaw Man OP  Opening「UHD 60FPS」.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Black Clover\\\\Black Clover - Opening 6 (HD).mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Saint Seya\\\\Pegasus Fantasy - Saint Seiya - original japanese opening - subtitled.mp4']}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blindTestSongDic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "answerTiming = r\"D:\\Videos\\Premiere Pro\\Project\\BlindTest\\EFX\\720p\\answer 720p.mp4\"\n",
    "countdownInterWaiting = r\"D:\\Videos\\Premiere Pro\\Project\\BlindTest\\EFX\\1080p\\cdwait2s.mp4\"\n",
    "countdownHid20 = r\"D:\\Videos\\Premiere Pro\\Project\\BlindTest\\EFX\\720p\\countdown20s720p.mp4\"\n",
    "\n",
    "fxDic = [countdownInterWaiting, countdownHid20, answerTiming]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a project\n",
    "project = pymiere.objects.app.project\n",
    "\n",
    "#Create sequences and bins\n",
    "#sequences = wrappers.list_sequences()\n",
    "sequence_preset_path = r\"C:\\Program Files\\Adobe\\Adobe Premiere Pro 2020\\Settings\\SequencePresets\\HDV\\HDV 720p30.sqpreset\"#r\"C:\\Program Files\\Adobe\\Adobe Premiere Pro 2020\\Settings\\SequencePresets\\ARRI\\1080p\\ARRI 1080p 23.976fps.sqpreset\"#TODO: find preset with 60 fps\n",
    "\n",
    "#Create Bins\n",
    "for sequenceNumb in range(1, batchNumber + 1):\n",
    "    #Create bin\n",
    "    project.rootItem.createBin('blindTest ' + str(sequenceNumb))\n",
    "\n",
    "    #Import Medias\n",
    "    project.importFiles(\n",
    "        blindTestSongDic['blindTest ' + str(sequenceNumb)], \n",
    "        suppressUI=True, \n",
    "        targetBin = project.rootItem.children[sequenceNumb - 1], \n",
    "        importAsNumberedStills=False) \n",
    "\n",
    "project.rootItem.createBin('EFX')\n",
    "pymiere.objects.app.project.rootItem.children[-1].setColorLabel(1) #set color for EFX bin\n",
    "\n",
    "project.importFiles(fxDic, # can import a list of media  \n",
    "suppressUI=True,  \n",
    "targetBin = project.rootItem.children[project.rootItem.children.numItems-1],  #project.getInsertionBin()\n",
    "importAsNumberedStills=False) \n",
    "#project.activeSequence = sequences[0]\n",
    "\n",
    "#Create sequences\n",
    "for sequenceNumb in range(1, batchNumber + 1):\n",
    "    sequence_name = list(blindTestSongDic.keys())[sequenceNumb - 1]\n",
    "    pymiere.objects.qe.project.newSequence(sequence_name, sequence_preset_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blindTest 1\n",
      "blindTest 2\n",
      "blindTest 3\n",
      "400.0\n",
      "260.1626016260162\n",
      "106.66666666666667\n",
      "blindTest 4\n",
      "200.0\n",
      "266.66666666666663\n",
      "blindTest 5\n",
      "102.72873194221508\n",
      "266.66666666666663\n"
     ]
    }
   ],
   "source": [
    "sequences = pymiere.objects.app.project.sequences #[s for s in pymiere.objects.app.project.sequences ] pymiere.objects.app.project.sequences\n",
    "\n",
    "for keyIndex in range(len(blindTestSongDic.keys())):\n",
    "    blindTestNumber = list(blindTestSongDic.keys())[keyIndex]\n",
    "    print(blindTestNumber)\n",
    "    sequence = [s for s in sequences if s.name == blindTestNumber][0] #pymiere.objects.qe.project.newSequence(sequence_name, sequence_preset_path) \n",
    "\n",
    "    createMainClip(project, sequence, blindTestList = blindTestSongDic[blindTestNumber], fxDic = fxDic, doCut = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipVideo = sequence.videoTracks[0].clips[-1]\n",
    "clipAudio = sequence.audioTracks[0].clips[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = pymiere.objects.app.project.sequences\n",
    "sequence = sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#songItem = project.rootItem.findItemsMatchingMediaPath(blindTestSongDic['blindTest 1'][0], ignoreSubclips=False)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Audio Compressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyTubeCompressor(clip, threshold = .8, ratio = .07, gain = 0.534, autoGain = 0.534, Attack = 1, release = 10):\n",
    "    for component in clip.components:\n",
    "        if component.displayName == 'Tube-modeled Compressor':\n",
    "            for property in component.properties:\n",
    "                if 'Threshold' in property.displayName:#TODO: Not working, set as -60db\n",
    "                    property.setValue(threshold, True) #0.9 <=> -6db // .783 <=> -13db // .8 <=> -12db\n",
    "                if 'Ratio' in property.displayName:#TODO: Not working, set as -60db\n",
    "                    property.setValue(ratio, True)# .007 <=> ratio 3:1 // .105 <=> 4:1\n",
    "                if 'Attack' in property.displayName:#TODO: Not working, set as -60db\n",
    "                    property.setValue(Attack, True)# .007 <=> ratio 3:1\n",
    "                if 'Release' in property.displayName:#TODO: Not working, set as -60db\n",
    "                    property.setValue(release, True)# .007 <=> ratio 3:1\n",
    "                if 'Auto Makeup Gain' in property.displayName:#TODO: Not working, set as -60db\n",
    "                    property.setValue(autoGain, True)# .007 <=> ratio 3:1\n",
    "                # if 'Gain' in property.displayName:#TODO: Not working, set as -60db\n",
    "                #     property.setValue(gain, True)# 0.534 <=> 2db // 0.583 <=> 5db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in qe.getAudioTransitionList():\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add compressor to all song in all sequence in audio tracks 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pymiere.objects.app.enableQE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qe_project.getAudioEffectByName(\"Tube-modeled Compressor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "qe_project = pymiere.objects.qe.project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyAudioTrackTransition(audioTrackQE, strTransitionName, strTransitionTime):#apply audio transition to whole audio track\n",
    "    for clipAudioIndex in range(audioTrackQE.numItems):\n",
    "        if clipAudioIndex %2 != 0: # apply at the end of the audio clip\n",
    "            clipAudioQE = audioTrackQE.getItemAt(clipAudioIndex)\n",
    "            clipAudioQE.addTransition(qe_project.getAudioTransitionByName(strTransitionName), True,strTransitionTime)\n",
    "    print('Audio transition done')\n",
    "\n",
    "def applyVideoTrackTransition(videoTrackQE, strTransitionName, strTransitionTime):\n",
    "    for clipVideoIndex in range(videoTrackQE.numItems):#Video track\n",
    "        if clipVideoIndex %2 != 0: # apply at the end of the video clip\n",
    "            clipVideoQE = videoTrackQE.getItemAt(clipVideoIndex)\n",
    "            clipVideoQE.addTransition(qe_project.getVideoTransitionByName(strTransitionName), True,strTransitionTime)\n",
    "    print('Video transition done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio transition done\n",
      "Video transition done\n",
      "Audio transition done\n",
      "Video transition done\n",
      "Audio transition done\n",
      "Video transition done\n",
      "Audio transition done\n",
      "Video transition done\n",
      "Audio transition done\n",
      "Video transition done\n"
     ]
    }
   ],
   "source": [
    "for sequenceIndex in range(qe_project.numSequences):\n",
    "    sequenceQE = qe_project.getSequenceAt(sequenceIndex)\n",
    "    audioTrackQE = sequenceQE.getAudioTrackAt(0)  \n",
    "    videoTrackQE = sequenceQE.getVideoTrackAt(0)  \n",
    "\n",
    "    applyAudioTrackTransition(audioTrackQE, \"Constant Power\", '25')\n",
    "    applyVideoTrackTransition(videoTrackQE, \"Cross Dissolve\", '10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------blindTest 4-------------------\n",
      "-------------------blindTest 1-------------------\n",
      "-------------------blindTest 2-------------------\n",
      "-------------------blindTest 5-------------------\n",
      "-------------------blindTest 3-------------------\n"
     ]
    }
   ],
   "source": [
    "# clip = pymiere.objects.app.project.activeSequence.audioTracks[0].clips[0]  \n",
    "\n",
    "sequences = pymiere.objects.app.project.sequences\n",
    "\n",
    "for sequence in sequences:\n",
    "    print('-------------------' + sequence.name + '-------------------')\n",
    "    for audioClip in sequence.audioTracks[0].clips:\n",
    "        applyTubeCompressor(audioClip, threshold = .8, ratio = .105, gain = 0.583, autoGain = 0.0, Attack = 0.02, release = 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume\n",
      "Bypass\n",
      "Level\n",
      "Channel Volume\n",
      "Bypass\n",
      "Left \n",
      "Right \n"
     ]
    }
   ],
   "source": [
    "clip = pymiere.objects.app.project.activeSequence.audioTracks[0].clips[0]  \n",
    "# find our effect in components  \n",
    "for component in clip.components: \n",
    "    print(component.displayName)\n",
    "\n",
    "    for property in component.properties:\n",
    "        print(property.displayName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pymiere.objects.app.project.activeSequence.createMotionGraphicsTemplate(\"My Text Template\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opacity\n",
      "Motion\n"
     ]
    }
   ],
   "source": [
    "for i in pymiere.objects.app.project.activeSequence.videoTracks[0].clips[0].components:\n",
    "    print(i.displayName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant Power\n",
      "Constant Gain\n",
      "Exponential Fade\n"
     ]
    }
   ],
   "source": [
    "for i in qe_project.getAudioTransitionList():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additive Dissolve\n",
      "Band Slide\n",
      "Band Wipe\n",
      "Barn Doors\n",
      "Center Merge\n",
      "Center Peel\n",
      "Center Split\n",
      "Channel Map\n",
      "CheckerBoard\n",
      "Checker Wipe\n",
      "Clock Wipe\n",
      "Cross Dissolve\n",
      "Cross Stretch\n",
      "Cross Zoom\n",
      "Cube Spin\n",
      "Curtain\n",
      "Dip to Black\n",
      "Dip to White\n",
      "Displace\n",
      "Dither Dissolve\n",
      "Doors\n",
      "Film Dissolve\n",
      "Flip Over\n",
      "Fold Up\n",
      "Gradient Wipe\n",
      "Inset\n",
      "Iris Cross\n",
      "Iris Diamond\n",
      "Iris Points\n",
      "Iris Round\n",
      "Iris Shapes\n",
      "Iris Box\n",
      "Iris Star\n",
      "Luminance Map\n",
      "Multi-Spin\n",
      "Non-Additive Dissolve\n",
      "Page Peel\n",
      "Page Turn\n",
      "Paint Splatter\n",
      "Peel Back\n",
      "Pinwheel\n",
      "Push\n",
      "Radial Wipe\n",
      "Random Blocks\n",
      "Random Invert\n",
      "Random Wipe\n",
      "Roll Away\n",
      "Slash Slide\n",
      "Slide\n",
      "Sliding Bands\n",
      "Sliding Boxes\n",
      "Spin\n",
      "Spin Away\n",
      "Spiral Boxes\n",
      "Split\n",
      "Stretch\n",
      "Stretch In\n",
      "Stretch Over\n",
      "Swap\n",
      "Swing In\n",
      "Swing Out\n",
      "Swirl\n",
      "Texturize\n",
      "Three-D\n",
      "Tumble Away\n",
      "Venetian Blinds\n",
      "Wedge Wipe\n",
      "Wipe\n",
      "Zig-Zag Blocks\n",
      "Zoom\n",
      "Zoom Boxes\n",
      "Zoom Trails\n",
      "Cross Dissolve\n",
      "Dip to Black\n",
      "Dip to White\n",
      "Morph Cut\n",
      "VR Chroma Leaks\n",
      "VR Gradient Wipe\n",
      "VR Iris Wipe\n",
      "VR Light Leaks\n",
      "VR Light Rays\n",
      "VR Mobius Zoom\n",
      "VR Random Blocks\n",
      "VR Spherical Blur\n"
     ]
    }
   ],
   "source": [
    "for i in qe_project.getVideoTransitionList():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "constant Power : interpose 2 clips pour une meilleur transition\n",
    "constant gain:\n",
    "exponential fade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Audio'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip.mediaType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip = pymiere.objects.app.project.activeSequence.videoTracks[0].clips[0]  \n",
    "# # find our effect in components  \n",
    "# for component in clip.components:  \n",
    "#     print(component.displayName)\n",
    "#     if component.displayName == \"Simple Text\":  \n",
    "#         break  \n",
    "\n",
    "# for property, property_name in zip(component.properties, [\"?\", \"Position\", \"Justification\", \"Size\", \"Opacity\", \"Content\"]):  \n",
    "#     if property_name == \"Position\":  \n",
    "#         property.setValue([0, 0], True)  \n",
    "#     if property_name == \"Content\":  \n",
    "#         property.setValue(\"NARUTO\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymiere.core.PymiereGenericObject at 0x26f9e777ca0>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pymiere.objects.app.anywhere.listProductions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Opacity----\n",
      "Opacity\n",
      "Blend Mode\n",
      "Blend Mode\n",
      "----Motion----\n",
      "Position\n",
      "Scale\n",
      "Scale Width\n",
      " \n",
      "Rotation\n",
      "Anchor Point\n",
      "Anti-flicker Filter\n"
     ]
    }
   ],
   "source": [
    "clip = pymiere.objects.app.project.activeSequence.videoTracks[0].clips[0]  \n",
    "\n",
    "effect = clip.components\n",
    "for component in effect:\n",
    "    print('----' + component.displayName + '----')\n",
    "    for property in component.properties:\n",
    "        print(property.displayName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# qe_project = pymiere.objects.qe.project \n",
    "\n",
    "# # get first clip of first video track  \n",
    "# track = qe_project.getActiveSequence().getVideoTrackAt(0)  \n",
    "# for x in range(track.numItems):  \n",
    "#     clip = track.getItemAt(x)  \n",
    "#     if clip.type != \"Empty\":  \n",
    "#         break  \n",
    "# # add Twirl video effect on clip\n",
    "# clip.addVideoEffect(qe_project.getVideoEffectByName(\"Simple Text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip = pymiere.objects.app.project.activeSequence.videoTracks[0].clips[0]  \n",
    "# # find our effect in components  \n",
    "# for component in clip.components:  \n",
    "#     if component.displayName == \"Simple Text\":  \n",
    "#         break  \n",
    "# else:  \n",
    "#     raise BaseException(\"No effect 'Simple Text' found on first clip\")  \n",
    "# # change some properties value or get the value  \n",
    "# for property, property_name in zip(component.properties, [\"?\", \"Position\", \"Justification\", \"Size\", \"Opacity\", \"Content\"]):  \n",
    "#     # if property_name == \"Position\":  \n",
    "#     #     property.setValue([0.5, 0.5], True)  \n",
    "#     if property_name == \"Content\":  \n",
    "#         property.setValue(\"Test \", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62057b160b158bade05a0be7ca25023f9a65060b811c92933e11c9c848fceaec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
