{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "\n",
    "import pymiere\n",
    "from pymiere import wrappers\n",
    "from pymiere.wrappers import get_system_sequence_presets\n",
    "from pymiere.wrappers import time_from_seconds    \n",
    "from pymiere.wrappers import check_active_sequence\n",
    "from pymiere.wrappers import list_sequences\n",
    "from pymiere.wrappers import list_video\n",
    "from pymiere.wrappers import edit_clip\n",
    "from pymiere.exe_utils import start_premiere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getListOfFiles(dirName):\n",
    "    # create a list of file and sub directories \n",
    "    # names in the given directory \n",
    "    listOfFile = os.listdir(dirName)\n",
    "    allFiles = list()\n",
    "    # Iterate over all the entries\n",
    "    for entry in listOfFile:\n",
    "        # Create full path\n",
    "        fullPath = os.path.join(dirName, entry)\n",
    "        # If entry is a directory then get the list of files in this directory \n",
    "        if os.path.isdir(fullPath):\n",
    "            allFiles = allFiles + getListOfFiles(fullPath)\n",
    "        else:\n",
    "            allFiles.append(fullPath)\n",
    "                \n",
    "    return allFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildAnimeDicPath(animeSongPath):\n",
    "    animeFolderList = [ f.path for f in os.scandir(animeSongPath) if f.is_dir() ]#os.listdir(animeSongPath)\n",
    "    animeDicPath = {}\n",
    "\n",
    "    for folder in os.listdir(animeSongPath): # build dictionnary of anime folder and song path in\n",
    "        animeDicPath[folder]= [ f.path for f in os.scandir(animeSongPath + '\\\\' + folder) if f.is_file() ]\n",
    "\n",
    "    return animeDicPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRandomSongPath(animeDicPath, batchNumber, songByBatch):# Create a dictionary of list of song \n",
    "    blindTestSongDic = {}\n",
    "    blindTestSongDic = {'blindTest ' + str(i): [] for i in range(1,batchNumber +1)} # inizialise number of batch\n",
    "\n",
    "    for key, value in blindTestSongDic.items():\n",
    "        for songIndex in range(songByBatch):# Number of song in a batch\n",
    "            \n",
    "            playlist = list(animeDicPath.keys())\n",
    "            animeNumber = len(playlist)\n",
    "            \n",
    "            playlist = playlist[random.randint(0,animeNumber)-1]#get a random anime\n",
    "            songPathList = animeDicPath[playlist] #get list of song path for that playlist\n",
    "            playlistSongNumber = len(songPathList) #get number of song for that anime\n",
    "\n",
    "            if playlistSongNumber != 0: #Folder has to have a song DL at the begining\n",
    "                print\n",
    "                song = songPathList[random.randint(0,playlistSongNumber)-1]\n",
    "\n",
    "                animeDicPath[playlist].remove(song)\n",
    "                if len(animeDicPath[playlist]) == 0:\n",
    "                    animeDicPath.pop(playlist)\n",
    "                blindTestSongDic[key].append(song)\n",
    "            else:\n",
    "                print('No song in the playlist at the begining: ', playlist)\n",
    "                animeDicPath.pop(playlist)\n",
    "                pass\n",
    "\n",
    "\n",
    "    return blindTestSongDic #TODO: CAN HAVE SAME SONG, TO CHECK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trim block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLastClip(sequence,videoTrackIndex):\n",
    "    #Video\n",
    "    lastClipVideo = sequence.videoTracks[videoTrackIndex].clips[-1]\n",
    "\n",
    "    #Audio\n",
    "    lastClipAudio = sequence.audioTracks[videoTrackIndex].clips[-1]\n",
    "\n",
    "    return lastClipVideo, lastClipAudio\n",
    "\n",
    "def trimEnd(videoClip, audioClip, videoClipTrack3 = None, audioClipTrack3 = None, endShift = 0):\n",
    "    if videoClipTrack3 and audioClipTrack3: # If a countdown clip exists, then trim w.r.t\n",
    "        #Video\n",
    "        videoClip.end = time_from_seconds(videoClipTrack3.end.seconds + endShift)\n",
    "\n",
    "        #Audio\n",
    "        audioClip.end = time_from_seconds(audioClipTrack3.end.seconds + endShift)\n",
    "    else: # If none, then flat trim\n",
    "        #Video\n",
    "        videoClip.end = time_from_seconds(videoClip.end.seconds - endShift)\n",
    "\n",
    "        #Audio\n",
    "        audioClip.end = time_from_seconds(audioClip.end.seconds - endShift)\n",
    "\n",
    "def trimStart(videoClip, audioClip, startShift):\n",
    "    # fpsClip = lastClipVideo.projectItem.getFootageInterpretation().frameRate\n",
    "    # shiftFrame = cutStartSecond * fpsClip\n",
    "    # lenClip = lastClipVideo.end.seconds - lastClipVideo.start.seconds\n",
    "\n",
    "    #Move clip LEFT\n",
    "    # try:\n",
    "    #     edit_clip(lastClipVideo, start_on_timeline=round(sequence.videoTracks[1].clips[-1].end.seconds*fpsClip), end_on_timeline=(lenClip-cutStartSecond)*fpsClip + round(sequence.videoTracks[1].clips[-1].end.seconds*fpsClip), in_point_on_clip=cutStartSecond*fpsClip, out_point_on_clip=(lenClip)*fpsClip, fps = fpsClip)\n",
    "    #     edit_clip(lastClipAudio, start_on_timeline=round(sequence.videoTracks[1].clips[-1].end.seconds*fpsClip), end_on_timeline=(lenClip-cutStartSecond)*fpsClip + round(sequence.videoTracks[1].clips[-1].end.seconds*fpsClip), in_point_on_clip=cutStartSecond*fpsClip, out_point_on_clip=(lenClip)*fpsClip, fps = fpsClip)\n",
    "    # except:                    \n",
    "    #     edit_clip(lastClipVideo, start_on_timeline=0, end_on_timeline=(lenClip-cutStartSecond)*fpsClip + 0, in_point_on_clip=cutStartSecond*fpsClip, out_point_on_clip=(lenClip)*fpsClip, fps = fpsClip)\n",
    "    #     edit_clip(lastClipAudio, start_on_timeline=0, end_on_timeline=(lenClip-cutStartSecond)*fpsClip + 0, in_point_on_clip=cutStartSecond*fpsClip, out_point_on_clip=(lenClip)*fpsClip, fps = fpsClip)\n",
    "    pass\n",
    "\n",
    "def trimClip(videoClip, audioClip, videoClipTrack3 = None, audioClipTrack3 = None, startShift = 0, endShift = 0):#TO MODIFY\n",
    "    if startShift != 0:\n",
    "        trimStart(videoClip, audioClip, startShift)\n",
    "    if endShift != 0:\n",
    "        trimEnd(videoClip, audioClip, videoClipTrack3, audioClipTrack3, endShift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVideoRes(videoPath):#TODO: Find a way to get clip resolution through premiere pro and not windows, to rename getClipRes\n",
    "    vcap = cv2.VideoCapture(videoPath) # 0=camera\n",
    " \n",
    "    if vcap.isOpened(): \n",
    "        # get vcap property \n",
    "        width  = int(vcap.get(3))  # float `width`\n",
    "        height = int(vcap.get(4))  # float `height`\n",
    "        fps = vcap.get(5)\n",
    "\n",
    "    return width, height, fps\n",
    "\n",
    "def getSequenceRes(sequence):\n",
    "    return sequence.frameSizeHorizontal, sequence.frameSizeVertical, 0 #TODO: find Sequence FPS\n",
    "\n",
    "def getSeqClipRatio(sequence, videoPath):\n",
    "    sequenceWidth,sequenceHeight, sequenceFPS = getSequenceRes(sequence)\n",
    "    videoWidth, videoHeight, videoFPS = getVideoRes(videoPath)\n",
    "\n",
    "    sequenceRes = sequenceWidth * sequenceHeight\n",
    "    videoRes = videoWidth * videoHeight\n",
    "\n",
    "    seqVidRatio = sequenceWidth/videoWidth*100#sequenceRes / videoRes * 100 # transform as percentage\n",
    "\n",
    "    return seqVidRatio\n",
    "\n",
    "def adjustScaleClip(clip, scaleValue):\n",
    "    for component in clip.components:  \n",
    "        if component.displayName == 'Motion':\n",
    "            for property in component.properties:\n",
    "                #print(property.displayName)\n",
    "                if property.displayName == 'Scale':\n",
    "                    property.setValue(scaleValue, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMainClip(project, sequence, blindTestList, fxDic, doCut):\n",
    "    cutStartSecond, cutEndSecond = 0, 15 #TODO: if cutStartSecond !=0, video are not synchronised\n",
    "\n",
    "    countDownVideoTrack = 2 \n",
    "\n",
    "    for index, songPath in enumerate(blindTestList):\n",
    "        #Import video on main track\n",
    "        songItem = project.rootItem.findItemsMatchingMediaPath(songPath, ignoreSubclips=False)[0]\n",
    "        try:\n",
    "            sequence.insertClip(songItem, time_from_seconds(sequence.videoTracks[countDownVideoTrack].clips[-1].end.seconds),0, 0)\n",
    "        except:\n",
    "            sequence.insertClip(songItem, time_from_seconds(0),0, 0)\n",
    "\n",
    "        lastClipVideo, lastClipAudio = getLastClip(sequence,videoTrackIndex = 0)\n",
    "        \n",
    "        #Adjust ratio if width are different\n",
    "        ratio = getSeqClipRatio(sequence, songPath)\n",
    "        adjustScaleClip(lastClipVideo, ratio)\n",
    "\n",
    "        if ratio != 100:\n",
    "            print(ratio)\n",
    "\n",
    "        sequence.insertClip(project.rootItem.findItemsMatchingMediaPath(fxDic[1], ignoreSubclips=False)[0], time_from_seconds(sequence.videoTracks[0].clips[-1].start.seconds), countDownVideoTrack, countDownVideoTrack)\n",
    "        #sequence.insertClip(project.rootItem.findItemsMatchingMediaPath(fxDic[2], ignoreSubclips=False)[0], time_from_seconds(sequence.videoTracks[countDownVideoTrack].clips[-1].end.seconds), countDownVideoTrack, countDownVideoTrack)\n",
    "\n",
    "        if doCut: #cut clip start and end\n",
    "            lastClipVideo3, lastClipAudio3 = getLastClip(sequence,videoTrackIndex = countDownVideoTrack)\n",
    "            #lastClipVideo3, lastClipAudio3 = None, None\n",
    "            trimClip(lastClipVideo, lastClipAudio, lastClipVideo3, lastClipAudio3, cutStartSecond, cutEndSecond)#TODO: TO MODIFY, CUT DOES NOT WORK AS INTENDED\n",
    "\n",
    "        #Waiting video in between main clip, This need to be last on the task list\n",
    "        if index < len(blindTestList)-1:#Do not create waiting countdown at the last video\n",
    "            sequence.insertClip(project.rootItem.findItemsMatchingMediaPath(fxDic[0], ignoreSubclips=False)[0], time_from_seconds(sequence.videoTracks[0].clips[-1].end.seconds), countDownVideoTrack,  countDownVideoTrack) \n",
    "\n",
    "        sequence.audioTracks[countDownVideoTrack].setMute(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "animeSongPath = r\"D:\\Videos\\Blind Test\\Anime\"\n",
    "animeSongList = getListOfFiles(animeSongPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doGetRandomSong = True\n",
    "\n",
    "batchNumber = 1\n",
    "songByBatch = 50\n",
    "\n",
    "if doGetRandomSong:\n",
    "    animeDicPath = buildAnimeDicPath(animeSongPath)\n",
    "    blindTestSongDic = getRandomSongPath(animeDicPath, batchNumber, songByBatch)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blindTest 1': ['D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Evangelion\\\\Neon Genesis Evangelion Opening (Zankoku na Tenshi no TEEZE) with Closed Captions.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\bakemonogatari\\\\Bakemonogatari - op 4 PL [Sengoku Nadeko].mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Shokugeki no Soma\\\\Food Wars! The Fourth Plate - Opening (HD).mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Saiki Kusuo no Psi nan\\\\The Disastrous Life of Saiki K – Opening Theme 1 – Youth Isnt So Cruel.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Rave Master\\\\Groove Adventure Rave op.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Kyoukai no Kanata\\\\Kyoukai No Kanata OP 60 FPS.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Ken le Survivant\\\\Générique  Ken le Survivant.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Toradora\\\\Toradora! - Lost My Pieces (OST).mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Hyouka\\\\Hyouka Opening 1.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Dr Stone\\\\ＴＶアニメ 「DrSTONE」 第1クールOP＜Good Morning World!＞ノンクレジット映像.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Koutetsujou no Kabaneri\\\\Most Epic Battle Anime Ost- WarCry (Kabaneri of the Iron Fortress).mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Ballroom e Youkoso\\\\Ballroom e Youkoso opening 1.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Kami no Tou\\\\Tower of God - Opening  TOP.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Ao no Exorcist\\\\「Creditless」Blue Exorcist OP  Opening 2「UHD 60FPS」.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Goblin Slayer\\\\GOBLIN SLAYER - Opening  Rightfully.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Tengen Toppa Gurren Lagann\\\\Tengen Toppa Gurren Lagann-Sorairo Days (Opening 1).mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Nausicaa\\\\Nausicaä theme (lalala)  Requiem.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Tokyo Revengers\\\\Tokyo Revengers - Opening  Cry Baby.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\SSBU\\\\Super Smash Bros Ultimate Main Theme - Lifelight.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Code Geass\\\\[HQ] Code Geass - Opening 2 - ♪♪ Kaidoku Funou ♪♪.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Tokyo Ghoul\\\\ノンテロップスペシャル版\\u3000TVアニメ「東京喰種トーキョーグール」オープニング映像 TK from 凛として時雨unravel.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Shaman King21\\\\TVアニメ『SHAMAN KING』ノンクレジットオープニング｜2021年4月1日放送開始.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\GrandBlue\\\\[HD] ぐらんぶる GRAND BLUE OP [湘南乃風 - Grand Blue].mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Koutetsujou no Kabaneri\\\\Koutetsujou no Kabaneri - ED TV Size [ ninelie ].mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Fairy Tail\\\\Fairy Tail - Opening 15  Masayume Chasing.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Hai to Gensou no Grimgar\\\\『灰と幻想のグリムガル』ノンテロップOP.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Higurashi no Naku Koro Ni\\\\Higurashi no Naku Koro Ni OPENING [Creditless][DVD-Rip].mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Koutetsujou no Kabaneri\\\\Koutetsujou no Kabaneri - Opening 1 [HD].mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Domestic Girlfriend\\\\Kawaki wo Ameku (カワキヲアメク) by Minami  Domestic Girlfriend.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Fate\\\\Fate Zero Op 2 [NC].mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Shaman King\\\\林原めぐみ 「Over Soul」  SHAMAN KING  オープニング.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Kimetsu no Yaiba\\\\Demon Slayer - Opening 2 by Lisa “Akeboshi” 4K 60FPS.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Danmachi\\\\Danmachi Opening 1.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Mirai Nikki\\\\Mirai Nikki Opening 2 English Sub.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Steins Gate\\\\SteinsGate Opening HD 1080p Creditless.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Cowboy Bebop\\\\Cowboy Bebop opening (Tank!).mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Laputa\\\\Castle in the Sky - Kimi wo Nosete  Carrying You  君をのせて.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Mob Psycho 100\\\\Mob Psycho 100 ENDING  Refrain Boy (HD).mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Hunter x Hunter\\\\Hunter X Hunter - Ending 4  Nagareboshi Kirari.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Gakusen Toshi Asterisk\\\\The Asterisk War - Opening 1  4K  60FPS  Creditless .mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Monster\\\\Monster Opening HD.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Boruto\\\\Boruto Naruto the Movie OST - Spin and Burst.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Tokyo Revengers\\\\Tokyo Revengers - Ending  Koko de Iki o Shite.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\91 Days\\\\91 Days - Opening  Signal.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Pokemon\\\\Lugias Song (Original).mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Yu Yu Hakusho\\\\Yu Yu Hakusho Opening 1 in Japanese.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Assassination Classroom\\\\Assassination Classroom Season 2 Ending 2.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Darling in the Franxx\\\\DARLING in the FRANXX – Opening Theme – KISS OF DEATH.mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\Naruto\\\\Naruto Opening 5  Seishun Kyousoukyoku (HD).mp4',\n",
       "  'D:\\\\Videos\\\\Blind Test\\\\Anime\\\\GrandBlue\\\\Grand Blue Anime TV-size Opening.mp4']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blindTestSongDic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "answerTiming = r\"D:\\Videos\\Premiere Pro\\Project\\BlindTest\\EFX\\720p\\answer 720p.mp4\"\n",
    "countdownInterWaiting = r\"D:\\Videos\\Premiere Pro\\Project\\BlindTest\\EFX\\1080p\\cdwait2s.mp4\"\n",
    "countdownHid20 = r\"D:\\Videos\\Premiere Pro\\Project\\BlindTest\\EFX\\720p\\countdown20s720p.mp4\"\n",
    "\n",
    "fxDic = [countdownInterWaiting, countdownHid20, answerTiming]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a project\n",
    "project = pymiere.objects.app.project\n",
    "\n",
    "#Create sequences and bins\n",
    "#sequences = wrappers.list_sequences()\n",
    "sequence_preset_path = r\"C:\\Program Files\\Adobe\\Adobe Premiere Pro 2020\\Settings\\SequencePresets\\HDV\\HDV 720p30.sqpreset\"#r\"C:\\Program Files\\Adobe\\Adobe Premiere Pro 2020\\Settings\\SequencePresets\\ARRI\\1080p\\ARRI 1080p 23.976fps.sqpreset\"#TODO: find preset with 60 fps\n",
    "\n",
    "#Create Bins\n",
    "for sequenceNumb in range(1, batchNumber + 1):\n",
    "    #Create bin\n",
    "    project.rootItem.createBin('blindTest ' + str(sequenceNumb))\n",
    "\n",
    "    #Import Medias\n",
    "    project.importFiles(\n",
    "        blindTestSongDic['blindTest ' + str(sequenceNumb)], \n",
    "        suppressUI=True, \n",
    "        targetBin = project.rootItem.children[sequenceNumb - 1], \n",
    "        importAsNumberedStills=False) \n",
    "\n",
    "project.rootItem.createBin('EFX')\n",
    "pymiere.objects.app.project.rootItem.children[-1].setColorLabel(1) #set color for EFX bin\n",
    "\n",
    "project.importFiles(fxDic, # can import a list of media  \n",
    "suppressUI=True,  \n",
    "targetBin = project.rootItem.children[project.rootItem.children.numItems-1],  #project.getInsertionBin()\n",
    "importAsNumberedStills=False) \n",
    "#project.activeSequence = sequences[0]\n",
    "\n",
    "#Create sequences\n",
    "for sequenceNumb in range(1, batchNumber + 1):\n",
    "    sequence_name = list(blindTestSongDic.keys())[sequenceNumb - 1]\n",
    "    pymiere.objects.qe.project.newSequence(sequence_name, sequence_preset_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blindTest 1\n",
      "400.0\n",
      "106.66666666666667\n",
      "266.66666666666663\n",
      "200.0\n",
      "266.66666666666663\n",
      "400.0\n",
      "266.66666666666663\n",
      "200.0\n"
     ]
    }
   ],
   "source": [
    "sequences = pymiere.objects.app.project.sequences #[s for s in pymiere.objects.app.project.sequences ] pymiere.objects.app.project.sequences\n",
    "\n",
    "for keyIndex in range(len(blindTestSongDic.keys())):\n",
    "    blindTestNumber = list(blindTestSongDic.keys())[keyIndex]\n",
    "    print(blindTestNumber)\n",
    "    sequence = [s for s in sequences if s.name == blindTestNumber][0] #pymiere.objects.qe.project.newSequence(sequence_name, sequence_preset_path) \n",
    "\n",
    "    createMainClip(project, sequence, blindTestList = blindTestSongDic[blindTestNumber], fxDic = fxDic, doCut = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipVideo = sequence.videoTracks[0].clips[-1]\n",
    "clipAudio = sequence.audioTracks[0].clips[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = pymiere.objects.app.project.sequences\n",
    "sequence = sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#songItem = project.rootItem.findItemsMatchingMediaPath(blindTestSongDic['blindTest 1'][0], ignoreSubclips=False)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Audio Compressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyTubeCompressor(clip, threshold = .8, ratio = .07, gain = 0.534, autoGain = 0.534, Attack = 1, release = 10):\n",
    "    for component in clip.components:\n",
    "        if component.displayName == 'Tube-modeled Compressor':\n",
    "            for property in component.properties:\n",
    "                if 'Threshold' in property.displayName:#TODO: Not working, set as -60db\n",
    "                    property.setValue(threshold, True) #0.9 <=> -6db // .783 <=> -13db // .8 <=> -12db\n",
    "                if 'Ratio' in property.displayName:#TODO: Not working, set as -60db\n",
    "                    property.setValue(ratio, True)# .007 <=> ratio 3:1 // .105 <=> 4:1\n",
    "                if 'Attack' in property.displayName:#TODO: Not working, set as -60db\n",
    "                    property.setValue(Attack, True)# .007 <=> ratio 3:1\n",
    "                if 'Release' in property.displayName:#TODO: Not working, set as -60db\n",
    "                    property.setValue(release, True)# .007 <=> ratio 3:1\n",
    "                if 'Auto Makeup Gain' in property.displayName:#TODO: Not working, set as -60db\n",
    "                    property.setValue(autoGain, True)# .007 <=> ratio 3:1\n",
    "                # if 'Gain' in property.displayName:#TODO: Not working, set as -60db\n",
    "                #     property.setValue(gain, True)# 0.534 <=> 2db // 0.583 <=> 5db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-07132ed86098>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mqe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetAudioTransitionList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'qe' is not defined"
     ]
    }
   ],
   "source": [
    "for i in qe.getAudioTransitionList():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add compressor to all song in all sequence in audio tracks 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pymiere.objects.app.enableQE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'PymiereGenericObject' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-33e921e1872d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mqe_project\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetAudioEffectByName\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Tube-modeled Compressor\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'PymiereGenericObject' object is not iterable"
     ]
    }
   ],
   "source": [
    "qe_project.getAudioEffectByName(\"Tube-modeled Compressor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "qe_project = pymiere.objects.qe.project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyAudioTrackTransition(audioTrackQE, strTransitionName, strTransitionTime):#apply audio transition to whole audio track\n",
    "    for clipAudioIndex in range(audioTrackQE.numItems):\n",
    "        if clipAudioIndex %2 != 0: # apply at the end of the audio clip\n",
    "            clipAudioQE = audioTrackQE.getItemAt(clipAudioIndex)\n",
    "            clipAudioQE.addTransition(qe_project.getAudioTransitionByName(strTransitionName), True,strTransitionTime)\n",
    "    print('Audio transition done')\n",
    "\n",
    "def applyVideoTrackTransition(videoTrackQE, strTransitionName, strTransitionTime):\n",
    "    for clipVideoIndex in range(videoTrackQE.numItems):#Video track\n",
    "        if clipVideoIndex %2 != 0: # apply at the end of the video clip\n",
    "            clipVideoQE = videoTrackQE.getItemAt(clipVideoIndex)\n",
    "            clipVideoQE.addTransition(qe_project.getVideoTransitionByName(strTransitionName), True,strTransitionTime)\n",
    "    print('Video transition done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio transition done\n",
      "Video transition done\n"
     ]
    }
   ],
   "source": [
    "for sequenceIndex in range(qe_project.numSequences):\n",
    "    sequenceQE = qe_project.getSequenceAt(sequenceIndex)\n",
    "    audioTrackQE = sequenceQE.getAudioTrackAt(0)  \n",
    "    videoTrackQE = sequenceQE.getVideoTrackAt(0)  \n",
    "\n",
    "    applyAudioTrackTransition(audioTrackQE, \"Constant Power\", '25')\n",
    "    applyVideoTrackTransition(videoTrackQE, \"Cross Dissolve\", '10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------blindTest 1-------------------\n"
     ]
    }
   ],
   "source": [
    "# clip = pymiere.objects.app.project.activeSequence.audioTracks[0].clips[0]  \n",
    "\n",
    "sequences = pymiere.objects.app.project.sequences\n",
    "\n",
    "for sequence in sequences:\n",
    "    print('-------------------' + sequence.name + '-------------------')\n",
    "    for audioClip in sequence.audioTracks[0].clips:\n",
    "        applyTubeCompressor(audioClip, threshold = .8, ratio = .105, gain = 0.583, autoGain = 0.0, Attack = 0.02, release = 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume\n",
      "Bypass\n",
      "Level\n",
      "Channel Volume\n",
      "Bypass\n",
      "Left \n",
      "Right \n"
     ]
    }
   ],
   "source": [
    "clip = pymiere.objects.app.project.activeSequence.audioTracks[0].clips[0]  \n",
    "# find our effect in components  \n",
    "for component in clip.components: \n",
    "    print(component.displayName)\n",
    "\n",
    "    for property in component.properties:\n",
    "        print(property.displayName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequence' object has no attribute 'createMotionGraphicsTemplate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-23077718c68a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpymiere\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactiveSequence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreateMotionGraphicsTemplate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"My Text Template\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequence' object has no attribute 'createMotionGraphicsTemplate'"
     ]
    }
   ],
   "source": [
    "pymiere.objects.app.project.activeSequence.createMotionGraphicsTemplate(\"My Text Template\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opacity\n",
      "Motion\n"
     ]
    }
   ],
   "source": [
    "for i in pymiere.objects.app.project.activeSequence.videoTracks[0].clips[0].components:\n",
    "    print(i.displayName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant Power\n",
      "Constant Gain\n",
      "Exponential Fade\n"
     ]
    }
   ],
   "source": [
    "for i in qe_project.getAudioTransitionList():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additive Dissolve\n",
      "Band Slide\n",
      "Band Wipe\n",
      "Barn Doors\n",
      "Center Merge\n",
      "Center Peel\n",
      "Center Split\n",
      "Channel Map\n",
      "CheckerBoard\n",
      "Checker Wipe\n",
      "Clock Wipe\n",
      "Cross Dissolve\n",
      "Cross Stretch\n",
      "Cross Zoom\n",
      "Cube Spin\n",
      "Curtain\n",
      "Dip to Black\n",
      "Dip to White\n",
      "Displace\n",
      "Dither Dissolve\n",
      "Doors\n",
      "Film Dissolve\n",
      "Flip Over\n",
      "Fold Up\n",
      "Gradient Wipe\n",
      "Inset\n",
      "Iris Cross\n",
      "Iris Diamond\n",
      "Iris Points\n",
      "Iris Round\n",
      "Iris Shapes\n",
      "Iris Box\n",
      "Iris Star\n",
      "Luminance Map\n",
      "Multi-Spin\n",
      "Non-Additive Dissolve\n",
      "Page Peel\n",
      "Page Turn\n",
      "Paint Splatter\n",
      "Peel Back\n",
      "Pinwheel\n",
      "Push\n",
      "Radial Wipe\n",
      "Random Blocks\n",
      "Random Invert\n",
      "Random Wipe\n",
      "Roll Away\n",
      "Slash Slide\n",
      "Slide\n",
      "Sliding Bands\n",
      "Sliding Boxes\n",
      "Spin\n",
      "Spin Away\n",
      "Spiral Boxes\n",
      "Split\n",
      "Stretch\n",
      "Stretch In\n",
      "Stretch Over\n",
      "Swap\n",
      "Swing In\n",
      "Swing Out\n",
      "Swirl\n",
      "Texturize\n",
      "Three-D\n",
      "Tumble Away\n",
      "Venetian Blinds\n",
      "Wedge Wipe\n",
      "Wipe\n",
      "Zig-Zag Blocks\n",
      "Zoom\n",
      "Zoom Boxes\n",
      "Zoom Trails\n",
      "Cross Dissolve\n",
      "Dip to Black\n",
      "Dip to White\n",
      "Morph Cut\n",
      "VR Chroma Leaks\n",
      "VR Gradient Wipe\n",
      "VR Iris Wipe\n",
      "VR Light Leaks\n",
      "VR Light Rays\n",
      "VR Mobius Zoom\n",
      "VR Random Blocks\n",
      "VR Spherical Blur\n"
     ]
    }
   ],
   "source": [
    "for i in qe_project.getVideoTransitionList():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "constant Power : interpose 2 clips pour une meilleur transition\n",
    "constant gain:\n",
    "exponential fade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Audio'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip.mediaType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip = pymiere.objects.app.project.activeSequence.videoTracks[0].clips[0]  \n",
    "# # find our effect in components  \n",
    "# for component in clip.components:  \n",
    "#     print(component.displayName)\n",
    "#     if component.displayName == \"Simple Text\":  \n",
    "#         break  \n",
    "\n",
    "# for property, property_name in zip(component.properties, [\"?\", \"Position\", \"Justification\", \"Size\", \"Opacity\", \"Content\"]):  \n",
    "#     if property_name == \"Position\":  \n",
    "#         property.setValue([0, 0], True)  \n",
    "#     if property_name == \"Content\":  \n",
    "#         property.setValue(\"NARUTO\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymiere.core.PymiereGenericObject at 0x203b87032e0>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pymiere.objects.app.anywhere.listProductions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Opacity----\n",
      "Opacity\n",
      "Blend Mode\n",
      "Blend Mode\n",
      "----Motion----\n",
      "Position\n",
      "Scale\n",
      "Scale Width\n",
      " \n",
      "Rotation\n",
      "Anchor Point\n",
      "Anti-flicker Filter\n"
     ]
    }
   ],
   "source": [
    "clip = pymiere.objects.app.project.activeSequence.videoTracks[0].clips[0]  \n",
    "\n",
    "effect = clip.components\n",
    "for component in effect:\n",
    "    print('----' + component.displayName + '----')\n",
    "    for property in component.properties:\n",
    "        print(property.displayName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qe_project = pymiere.objects.qe.project \n",
    "\n",
    "# # get first clip of first video track  \n",
    "# track = qe_project.getActiveSequence().getVideoTrackAt(0)  \n",
    "# for x in range(track.numItems):  \n",
    "#     clip = track.getItemAt(x)  \n",
    "#     if clip.type != \"Empty\":  \n",
    "#         break  \n",
    "# # add Twirl video effect on clip\n",
    "# clip.addVideoEffect(qe_project.getVideoEffectByName(\"Simple Text\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62057b160b158bade05a0be7ca25023f9a65060b811c92933e11c9c848fceaec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
